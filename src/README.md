# LLM TabanlÄ± Sorgulama ve YanÄ±t Ãœretimi

**TÃœBÄ°TAK 1505 Projesi**  
**Sorumlular:** Hasan, Eren

## ğŸ“‹ Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#genel-bakÄ±ÅŸ)
- [Kurulum](#kurulum)
- [HÄ±zlÄ± BaÅŸlangÄ±Ã§](#hÄ±zlÄ±-baÅŸlangÄ±Ã§)
- [KullanÄ±m Ã–rnekleri](#kullanÄ±m-Ã¶rnekleri)
- [API DokÃ¼mantasyonu](#api-dokÃ¼mantasyonu)
- [YapÄ±landÄ±rma](#yapÄ±landÄ±rma)

## ğŸ¯ Genel BakÄ±ÅŸ

Bu modÃ¼l, TÃœBÄ°TAK 1505 Projesi kapsamÄ±nda LLM (Large Language Model) tabanlÄ± sorgulama ve yanÄ±t Ã¼retim altyapÄ±sÄ±nÄ± saÄŸlar. Sistem, iki farklÄ± LLM seÃ§eneÄŸi sunar:

1. **OpenAI API** - Bulut tabanlÄ± GPT modelleri
2. **Ollama** - Yerel olarak Ã§alÄ±ÅŸan aÃ§Ä±k kaynak modeller (Llama3, Gemma3-12B, Qwen2-8B)

### Temel Ã–zellikler

- âœ… OpenAI ve Ollama LLM desteÄŸi
- âœ… RAG (Retrieval-Augmented Generation) mimarisi
- âœ… Qdrant vektÃ¶r veritabanÄ± entegrasyonu
- âœ… KonuÅŸma geÃ§miÅŸi yÃ¶netimi
- âœ… FastAPI tabanlÄ± REST API
- âœ… GÃ¼venli metin iÅŸleme
- âœ… TÃ¼rkÃ§e ve Ä°ngilizce dil desteÄŸi

## ğŸš€ Kurulum

### Gereksinimler

- Python 3.8+
- Ollama (yerel LLM iÃ§in) veya OpenAI API anahtarÄ±
- Qdrant (opsiyonel, RAG iÃ§in)

### AdÄ±mlar

1. **BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:**

```bash
pip install -r requirements.txt
```

2. **Ortam deÄŸiÅŸkenlerini ayarlayÄ±n:**

```bash
cp .env.example .env
# .env dosyasÄ±nÄ± dÃ¼zenleyin ve API anahtarlarÄ±nÄ±zÄ± ekleyin
```

3. **Ollama'yÄ± yÃ¼kleyin ve baÅŸlatÄ±n (yerel LLM iÃ§in):**

```bash
# Ollama'yÄ± indirin: https://ollama.ai
ollama serve

# Model indirin
ollama pull llama3
# veya
ollama pull gemma3:12b
# veya
ollama pull qwen2:8b
```

## âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Basit OpenAI Ã–rneÄŸi

```python
from langchain_openai import OpenAI

llm = OpenAI(api_key="YOUR_OPENAI_API_KEY")
prompt = "TÃ¼rkiye'nin baÅŸkenti neresidir?"
response = llm.invoke(prompt)
print(response)
```

Veya Ã¶rnek scripti Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
export OPENAI_API_KEY="your-key-here"
python examples/simple_openai_example.py
```

### 2. Ollama ile Yerel LLM

```python
from src.llm_query import LLMQuerySystem

# Sistem oluÅŸtur
llm_system = LLMQuerySystem(use_openai=False)

# Sorgu yap
result = llm_system.query(
    prompt="TÃœBÄ°TAK 1505 programÄ± nedir?",
    language="tr"
)

print(result["response"])
```

Veya Ã¶rnek scripti Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python examples/ollama_example.py
```

### 3. RAG ile BaÄŸlam TabanlÄ± YanÄ±t

```python
from src.llm_query import LLMQuerySystem

llm_system = LLMQuerySystem(use_openai=False)

# BaÄŸlam ile sorgu
context = "TÃœBÄ°TAK 1505 ProgramÄ±, Ã¼niversite-sanayi iÅŸbirliÄŸi projelerini destekler..."
result = llm_system.query(
    prompt="TÃœBÄ°TAK 1505 neyi destekler?",
    context=context,
    language="tr"
)

print(result["response"])
```

Veya Ã¶rnek scripti Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python examples/rag_example.py
```

### 4. FastAPI Servisi

```bash
# Servisi baÅŸlat
cd src
python api_service.py

# Veya uvicorn ile
uvicorn src.api_service:app --reload --host 0.0.0.0 --port 8000
```

API'ye istek gÃ¶nder:

```bash
curl -X POST "http://localhost:8000/ask/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "TÃ¼rkiye'\''nin baÅŸkenti neresidir?",
    "use_openai": false,
    "language": "tr"
  }'
```

## ğŸ“š KullanÄ±m Ã–rnekleri

### Temel Sorgu

```python
from src.llm_query import LLMQuerySystem

# LLM sistemi oluÅŸtur
llm = LLMQuerySystem(use_openai=False)

# Sorgu yap
result = llm.query(prompt="Python nedir?")

if result["success"]:
    print(f"YanÄ±t: {result['response']}")
    print(f"Model: {result['model']}")
else:
    print(f"Hata: {result['error']}")
```

### LangChain Chain KullanÄ±mÄ±

```python
from src.llm_query import LLMQuerySystem

llm = LLMQuerySystem(use_openai=False)

# Ã–zel ÅŸablon ile sorgu
template = """Sen bir yapay zeka asistanÄ±sÄ±n.
Soru: {question}
YanÄ±t:"""

result = llm.query_with_chain(
    prompt="Yapay zeka nedir?",
    template=template
)

print(result["response"])
```

### KonuÅŸma GeÃ§miÅŸi

```python
from src.llm_query import LLMQuerySystem

llm = LLMQuerySystem(use_openai=False)

# Ä°lk sorgu
llm.query(prompt="Python nedir?")

# Ä°kinci sorgu (baÄŸlam korunur)
llm.query(prompt="Hangi alanlarda kullanÄ±lÄ±r?")

# GeÃ§miÅŸi gÃ¶rÃ¼ntÃ¼le
history = llm.get_conversation_history()
print(f"Toplam {len(history)} mesaj")

# GeÃ§miÅŸi temizle
llm.clear_memory()
```

## ğŸ”Œ API DokÃ¼mantasyonu

### Endpoint'ler

#### `POST /ask/`

Soru sor ve yanÄ±t al.

**Ä°stek GÃ¶vdesi:**
```json
{
  "question": "Soru metni",
  "document_id": "optional-doc-id",
  "collection_name": "optional-collection",
  "use_openai": false,
  "language": "tr"
}
```

**YanÄ±t:**
```json
{
  "success": true,
  "response": "LLM yanÄ±tÄ±",
  "model": "llama3",
  "sources": ["kaynak1", "kaynak2"],
  "error": null
}
```

#### `GET /health/`

Sistem durumu kontrolÃ¼.

**YanÄ±t:**
```json
{
  "status": "healthy",
  "qdrant_connected": true,
  "ollama_available": true,
  "openai_available": false
}
```

#### `POST /clear-memory/`

KonuÅŸma geÃ§miÅŸini temizle.

**Parametreler:**
- `use_openai`: boolean (varsayÄ±lan: false)

### Swagger DokÃ¼mantasyonu

API Ã§alÄ±ÅŸÄ±rken ÅŸu adreste interaktif dokÃ¼mantasyon bulunur:
- http://localhost:8000/docs (Swagger UI)
- http://localhost:8000/redoc (ReDoc)

## âš™ï¸ YapÄ±landÄ±rma

### Ortam DeÄŸiÅŸkenleri

`.env` dosyasÄ±nda aÅŸaÄŸÄ±daki deÄŸiÅŸkenleri ayarlayÄ±n:

```bash
# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=my_collection

# OpenAI
OPENAI_API_KEY=your-key-here
OPENAI_MODEL=gpt-3.5-turbo

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# LLM Parametreleri
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500
MEMORY_WINDOW_SIZE=5
TOP_K_RESULTS=5
```

### Model SeÃ§enekleri

#### OpenAI Modelleri
- `gpt-3.5-turbo` (hÄ±zlÄ±, ekonomik)
- `gpt-4` (daha gÃ¼Ã§lÃ¼, pahalÄ±)
- `gpt-4-turbo`

#### Ollama Modelleri
- `llama3` - Meta'nÄ±n gÃ¼Ã§lÃ¼ modeli
- `gemma3:12b` - Google'Ä±n 12B parametreli modeli
- `qwen2:8b` - Alibaba'nÄ±n 8B parametreli modeli
- `mistral` - Mistral AI modeli

## ğŸ“– DetaylÄ± DokÃ¼mantasyon

Daha fazla bilgi iÃ§in:

- [LLM YanÄ±t Sistemi Teknik Rehberi](../docs/4_llm_response_guide.md)
- [Tam Ä°ÅŸ AkÄ±ÅŸÄ±](../docs/5_complete_workflow.md)
- [Genel README](../README.md)

## ğŸ¤ KatkÄ±da Bulunanlar

- **Hasan** - LLM entegrasyonu ve yanÄ±t Ã¼retimi
- **Eren** - Qdrant entegrasyonu ve API geliÅŸtirme

## ğŸ“ Destek

Sorular iÃ§in lÃ¼tfen GitHub Issues bÃ¶lÃ¼mÃ¼nÃ¼ kullanÄ±n.
