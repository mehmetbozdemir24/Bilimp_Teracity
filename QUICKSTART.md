# Bilimp Terracity - HÄ±zlÄ± BaÅŸlangÄ±Ã§ KÄ±lavuzu

Bu kÄ±lavuz, Bilimp Terracity Asistan sistemini hÄ±zlÄ±ca kurmak ve kullanmaya baÅŸlamak iÃ§in adÄ±m adÄ±m talimatlar iÃ§erir.

## âš¡ HÄ±zlÄ± Kurulum (Linux/Mac)

```bash
# 1. Kurulum scriptini Ã§alÄ±ÅŸtÄ±r
chmod +x setup.sh
./setup.sh

# 2. LLM modellerini indir (bu iÅŸlem uzun sÃ¼rebilir)
docker exec -it bilimp_ollama ollama pull gemma3:12b
docker exec -it bilimp_ollama ollama pull qwen3:9b

# 3. Ã–rnek kullanÄ±mÄ± test et
python example_usage.py
```

## ğŸ“ Manuel Kurulum AdÄ±mlarÄ±

### 1. Ã–n Gereksinimler
```bash
# Python versiyonunu kontrol et
python3 --version  # 3.8 veya Ã¼zeri olmalÄ±

# Docker'Ä± kontrol et
docker --version
docker-compose --version

# Git'i kontrol et
git --version
```

### 2. Projeyi Ä°ndir
```bash
git clone https://github.com/mehmetbozdemir24/Bilimp_Terracity.git
cd Bilimp_Terracity
```

### 3. Python OrtamÄ±nÄ± HazÄ±rla
```bash
# Sanal ortam oluÅŸtur
python3 -m venv venv

# Sanal ortamÄ± aktifleÅŸtir
source venv/bin/activate  # Linux/Mac
# VEYA
venv\Scripts\activate  # Windows

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Ortam DeÄŸiÅŸkenlerini Ayarla
```bash
# .env dosyasÄ±nÄ± oluÅŸtur
cp .env.example .env

# Ä°steÄŸe baÄŸlÄ±: .env dosyasÄ±nÄ± dÃ¼zenle
nano .env  # veya baÅŸka bir editÃ¶r
```

### 5. Docker Servislerini BaÅŸlat
```bash
# Qdrant ve Ollama'yÄ± baÅŸlat
docker-compose up -d

# Servislerin durumunu kontrol et
docker ps

# LoglarÄ± kontrol et
docker logs bilimp_qdrant
docker logs bilimp_ollama
```

### 6. LLM Modellerini Ä°ndir
```bash
# Gemma3-12B (yaklaÅŸÄ±k 7GB)
docker exec -it bilimp_ollama ollama pull gemma3:12b

# Qwen3-9B (yaklaÅŸÄ±k 5GB)
docker exec -it bilimp_ollama ollama pull qwen3:9b

# Ä°ndirilen modelleri kontrol et
docker exec -it bilimp_ollama ollama list
```

## ğŸ¯ Temel KullanÄ±m

### AdÄ±m 1: DokÃ¼man Ekleme
```bash
# DokÃ¼manlarÄ±nÄ±zÄ± data/raw/ klasÃ¶rÃ¼ne kopyalayÄ±n
cp /path/to/your/documents/*.pdf data/raw/
cp /path/to/your/documents/*.docx data/raw/
```

### AdÄ±m 2: DokÃ¼manlarÄ± Ä°ÅŸleme
```bash
# Pipeline'Ä± Ã§alÄ±ÅŸtÄ±r (bu iÅŸlem zaman alabilir)
python main.py --mode process --input-dir data/raw
```

Bu komut:
- TÃ¼m dokÃ¼manlarÄ± okur
- Her dokÃ¼manÄ± chunk'lara ayÄ±rÄ±r
- Her chunk iÃ§in embedding Ã¼retir
- Embedding'leri Qdrant'a yÃ¼kler

### AdÄ±m 3: Sistemi Sorgulama
```bash
# Gemma3 modeli ile sorgulama
python main.py --mode query --query "Bilimp sistemi nedir?" --model gemma

# Qwen3 modeli ile sorgulama
python main.py --mode query --query "DokÃ¼man yÃ¶netimi nasÄ±l Ã§alÄ±ÅŸÄ±r?" --model qwen

# Model belirtmeden sorgulama (varsayÄ±lan: Gemma3)
python main.py --mode query --query "Temel Ã¶zellikler nelerdir?"
```

### AdÄ±m 4: Sistem Bilgisi
```bash
# VeritabanÄ± ve sistem bilgilerini gÃ¶ster
python main.py --mode info
```

## ğŸ“Š Ã–rnek Ã‡Ä±ktÄ±lar

### Process Mode
```
INFO - Processing documents from: data/raw
INFO - Found 3 supported files in data/raw
INFO - Processing file: data/raw/document1.pdf
INFO - Successfully loaded 10 pages from data/raw/document1.pdf
INFO - Created 45 chunks from documents
INFO - Generating embeddings
INFO - Generated 45 embeddings
INFO - Uploading to Qdrant database
INFO - Uploaded 45 chunks to database
INFO - Pipeline completed successfully
```

### Query Mode
```
================================================================================
Query: Bilimp sistemi nedir?
================================================================================

Retrieved 5 documents
Model: gemma3:12b

Response:
--------------------------------------------------------------------------------
Bilimp, Terracity firmasÄ± tarafÄ±ndan geliÅŸtirilen modern bir dokÃ¼man yÃ¶netim
sistemidir. Sistem, ÅŸirketlerin dokÃ¼manlarÄ±nÄ± dijital ortamda gÃ¼venli bir 
ÅŸekilde saklamasÄ±na, organize etmesine ve yÃ¶netmesine olanak tanÄ±r...
================================================================================
```

### Info Mode
```
================================================================================
Bilimp System Information
================================================================================
Collection: bilimp_documents
Documents: 145
Status: green
Embedding Model: intfloat/multilingual-e5-large
Embedding Dimension: 1024
LLM Models: gemma3:12b, qwen3:9b
================================================================================
```

## ğŸ”§ YapÄ±landÄ±rma Ä°puÃ§larÄ±

### Chunk Boyutunu Ayarlama
`.env` dosyasÄ±nda:
```env
CHUNK_SIZE=512        # Daha kÃ¼Ã§Ã¼k parÃ§alar iÃ§in azaltÄ±n (Ã¶rn: 256)
CHUNK_OVERLAP=50      # BaÄŸlam korunmasÄ± iÃ§in overlap ayarlayÄ±n
```

### Batch Size Optimizasyonu
```env
BATCH_SIZE=32         # GPU varsa artÄ±rÄ±n (64), yoksa azaltÄ±n (16)
```

### LLM Model AyarlarÄ±
```bash
# FarklÄ± model versiyonlarÄ± kullanmak iÃ§in
docker exec -it bilimp_ollama ollama pull gemma:7b  # Daha hÄ±zlÄ±
docker exec -it bilimp_ollama ollama pull llama2:13b  # Alternatif
```

## ğŸ› YaygÄ±n Sorunlar ve Ã‡Ã¶zÃ¼mler

### Problem: "Connection refused" hatasÄ±
```bash
# Ã‡Ã¶zÃ¼m: Servislerin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun
docker-compose ps
docker-compose up -d
```

### Problem: Model bulunamadÄ±
```bash
# Ã‡Ã¶zÃ¼m: Modeli indirin
docker exec -it bilimp_ollama ollama pull gemma3:12b
```

### Problem: Out of memory (OOM)
```bash
# Ã‡Ã¶zÃ¼m 1: Batch size'Ä± azaltÄ±n (.env dosyasÄ±nda)
BATCH_SIZE=8

# Ã‡Ã¶zÃ¼m 2: Daha kÃ¼Ã§Ã¼k model kullanÄ±n
docker exec -it bilimp_ollama ollama pull gemma:7b
```

### Problem: YavaÅŸ embedding Ã¼retimi
```bash
# Ã‡Ã¶zÃ¼m: GPU kullanÄ±mÄ±nÄ± kontrol edin
nvidia-smi  # CUDA var mÄ±?

# CUDA yoksa, CPU iÃ§in batch size'Ä± azaltÄ±n
BATCH_SIZE=16
```

## ğŸ“š Ek Kaynaklar

### Python API KullanÄ±mÄ±
```python
from main import BilimpPipeline

# Pipeline oluÅŸtur
pipeline = BilimpPipeline()
pipeline.initialize_components()

# DokÃ¼manlarÄ± iÅŸle
chunks = pipeline.process_documents("data/raw")
processed = pipeline.generate_embeddings(chunks)
pipeline.upload_to_database(processed)

# Sorgula
result = pipeline.query_system("Bilimp nedir?", model="gemma")
print(result['response'])
```

### Ã–rnek Script Ã‡alÄ±ÅŸtÄ±rma
```bash
# TÃ¼m Ã¶rnekleri gÃ¶rmek iÃ§in
python example_usage.py
```

## ğŸ“ Ã–ÄŸrenme Yolu

1. **BaÅŸlangÄ±Ã§**: `example_usage.py` dosyasÄ±nÄ± inceleyin
2. **ModÃ¼l DetaylarÄ±**: `src/` klasÃ¶rÃ¼ndeki modÃ¼lleri keÅŸfedin
3. **Ã–zelleÅŸtirme**: Kendi kullanÄ±m durumunuz iÃ§in kod yazÄ±n
4. **Optimizasyon**: Performans ayarlarÄ±nÄ± yapÄ±n

## ğŸ“ YardÄ±m

Sorun yaÅŸarsanÄ±z:
1. `docker logs bilimp_qdrant` ve `docker logs bilimp_ollama` loglarÄ±nÄ± kontrol edin
2. `.env` dosyasÄ±nÄ±n doÄŸru yapÄ±landÄ±rÄ±ldÄ±ÄŸÄ±ndan emin olun
3. Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ±n yÃ¼klÃ¼ olduÄŸunu kontrol edin: `pip list`
4. GitHub Issues'da yeni bir issue aÃ§Ä±n

## âœ… BaÅŸarÄ± KontrolÃ¼

Kurulum baÅŸarÄ±lÄ± olduysa:
- âœ“ `docker ps` Qdrant ve Ollama containerlarÄ±nÄ± gÃ¶sterir
- âœ“ `python main.py --mode info` sistem bilgilerini gÃ¶sterir
- âœ“ `example_usage.py` hatasÄ±z Ã§alÄ±ÅŸÄ±r
- âœ“ Test sorgusu yanÄ±t dÃ¶ner

Tebrikler! Sistem kullanÄ±ma hazÄ±r. ğŸ‰
