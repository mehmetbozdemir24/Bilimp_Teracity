{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "1jtFqPqTFGU1KVpNByvHApIFZAYhDK6PK",
      "authorship_tag": "ABX9TyNbOdVzV4CNPNVwno3uCzzX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehmetbozdemir24/Tubitak_1505_Proje/blob/chunking/chunk1505.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*code*"
      ],
      "metadata": {
        "id": "GJZavHlsKt5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import subprocess\n",
        "\n",
        "# Gerekli paketlerin kontrolü ve kurulumu\n",
        "def install_packages():\n",
        "    print(\"Gerekli kütüphaneler kuruluyor... Lütfen bekleyin.\")\n",
        "    packages = [\n",
        "        \"langchain\",\n",
        "        \"langchain-community\",\n",
        "        \"pypdf\",\n",
        "        \"openpyxl\",\n",
        "        \"pandas\",\n",
        "        \"python-docx\",\n",
        "        \"python-pptx\",\n",
        "        \"unstructured\",\n",
        "        \"networkx\"\n",
        "    ]\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + packages)\n",
        "    print(\"Kurulum tamamlandı.\")\n",
        "\n",
        "try:\n",
        "    import langchain\n",
        "    import pandas as pd\n",
        "except ImportError:\n",
        "    install_packages()\n",
        "    import pandas as pd"
      ],
      "metadata": {
        "id": "VtNTJtmOK0cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import (\n",
        "    PyPDFLoader,\n",
        "    Docx2txtLoader,\n",
        "    UnstructuredPowerPointLoader\n",
        ")\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n"
      ],
      "metadata": {
        "id": "3BEfhTK_LAO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ana Dizin Yolu\n",
        "BASE_PATH = \"/content/drive/MyDrive/1505 Chunking/Doküman\"\n",
        "\n",
        "# Hedef Klasörler\n",
        "TARGET_FOLDERS = [\"pdf\", \"excel\", \"word\", \"powerpoint\"]\n",
        "\n",
        "def get_file_permission(filename, folder_name):\n",
        "\n",
        "    filename_lower = filename.lower()\n",
        "\n",
        "    if any(keyword in filename_lower for keyword in [\"gizli\", \"maliyet\", \"yonetim\", \"admin\"]):\n",
        "        return \"admin\"\n",
        "\n",
        "    # Örnek Kural 2: Varsayılan olarak herkes (user)\n",
        "    return \"user\""
      ],
      "metadata": {
        "id": "CvITfzw-N0q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doküman işleme\n",
        "\n",
        "class DriveDocumentProcessor:\n",
        "    def __init__(self, chunk_size=1000, chunk_overlap=100):\n",
        "\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap\n",
        "        )\n",
        "        self.processed_chunks = []\n",
        "\n",
        "    def process_excel(self, file_path, permission):\n",
        "        \"\"\"\n",
        "        Excel dosyalarını satır satır okur ve bağlamsal chunklar oluşturur.\n",
        "        Her satır bir chunk veya birleştirilmiş metin olur.\n",
        "        \"\"\"\n",
        "        try:\n",
        "\n",
        "            xls = pd.read_excel(file_path, sheet_name=None)\n",
        "\n",
        "            for sheet_name, df in xls.items():\n",
        "                # Boş sütunları ve satırları temizle\n",
        "                df.dropna(how='all', axis=0, inplace=True)\n",
        "                df.dropna(how='all', axis=1, inplace=True)\n",
        "\n",
        "                # Tarih formatlarını string'e çevir\n",
        "                for col in df.columns:\n",
        "                    if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
        "                        df[col] = df[col].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "                # Her bir satırı bir metin bloğuna dönüştür\n",
        "                for index, row in df.iterrows():\n",
        "                    # Satır verisini \"Sütun Adı: Değer\" formatına getir\n",
        "                    row_content_list = []\n",
        "                    for col in df.columns:\n",
        "                        val = row[col]\n",
        "                        if pd.notna(val) and str(val).strip() != \"\":\n",
        "                            row_content_list.append(f\"{col}: {val}\")\n",
        "\n",
        "                    if not row_content_list:\n",
        "                        continue\n",
        "\n",
        "                    # Satırı tek bir metin haline getir\n",
        "                    row_text = f\"Tablo: {sheet_name}, Satır: {index+1}\\n\" + \"\\n\".join(row_content_list)\n",
        "\n",
        "                    # Metadata oluştur\n",
        "                    metadata = {\n",
        "                        \"source\": os.path.basename(file_path),\n",
        "                        \"sheet_name\": sheet_name,\n",
        "                        \"row_number\": index + 1,\n",
        "                        \"chunk_number\": len(self.processed_chunks) + 1,\n",
        "                        \"permission\": permission,\n",
        "                        \"file_type\": \"excel\",\n",
        "                        \"original_source\": file_path\n",
        "                    }\n",
        "\n",
        "                    doc = Document(page_content=row_text, metadata=metadata)\n",
        "                    self.processed_chunks.append(doc)\n",
        "\n",
        "            print(f\"  -> Excel işlendi: {len(xls)} sayfa.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  !! Excel hatası ({os.path.basename(file_path)}): {e}\")\n",
        "\n",
        "    def process_standard_file(self, file_path, file_type, permission):\n",
        "        \"\"\"PDF, Word ve PowerPoint için standart işleme.\"\"\"\n",
        "        loader = None\n",
        "        try:\n",
        "            if file_type == \"pdf\":\n",
        "                loader = PyPDFLoader(file_path)\n",
        "            elif file_type == \"word\":\n",
        "                loader = Docx2txtLoader(file_path)\n",
        "            elif file_type == \"powerpoint\":\n",
        "                loader = UnstructuredPowerPointLoader(file_path)\n",
        "\n",
        "            if not loader:\n",
        "                return\n",
        "\n",
        "            raw_docs = loader.load()\n",
        "            chunks = self.text_splitter.split_documents(raw_docs)\n",
        "\n",
        "            filename = os.path.basename(file_path)\n",
        "\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                # Sayfa numarasını güvenli alma\n",
        "                page = chunk.metadata.get(\"page\", chunk.metadata.get(\"page_number\", 1))\n",
        "                if isinstance(page, int) and file_type == \"pdf\":\n",
        "                     page += 1\n",
        "\n",
        "                enriched_meta = {\n",
        "                    \"source\": filename,\n",
        "                    \"page_number\": page,\n",
        "                    \"chunk_number\": len(self.processed_chunks) + 1,\n",
        "                    \"permission\": permission,\n",
        "                    \"file_type\": file_type,\n",
        "                    \"original_source\": file_path\n",
        "                }\n",
        "                chunk.metadata = enriched_meta\n",
        "                self.processed_chunks.append(chunk)\n",
        "\n",
        "            print(f\"  -> {file_type.upper()} işlendi: {len(chunks)} parça.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  !! Hata ({file_type} - {os.path.basename(file_path)}): {e}\")\n",
        "\n",
        "    def save_data(self, output_path):\n",
        "        with open(output_path, \"wb\") as f:\n",
        "            pickle.dump(self.processed_chunks, f)\n",
        "        print(f\"\\nToplam {len(self.processed_chunks)} chunk kaydedildi: {output_path}\")\n"
      ],
      "metadata": {
        "id": "JkX7nfwULlX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    processor = DriveDocumentProcessor()\n",
        "\n",
        "    print(f\"Tarama Başlıyor: {BASE_PATH}\")\n",
        "\n",
        "    if not os.path.exists(BASE_PATH):\n",
        "        print(f\"HATA: Belirtilen yol bulunamadı! -> {BASE_PATH}\")\n",
        "        print(\"Lütfen Drive yolunuzu kontrol edin.\")\n",
        "        return\n",
        "\n",
        "    # Klasörleri gez\n",
        "    for folder in TARGET_FOLDERS:\n",
        "        folder_path = os.path.join(BASE_PATH, folder)\n",
        "\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"Uyarı: Klasör bulunamadı, geçiliyor -> {folder}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n[{folder.upper()}] Klasörü Taranıyor...\")\n",
        "\n",
        "        files = os.listdir(folder_path)\n",
        "        if not files:\n",
        "            print(\"  (Klasör boş)\")\n",
        "\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Gizli dosyaları (.DS_Store vs) atla\n",
        "            if filename.startswith(\".\"):\n",
        "                continue\n",
        "\n",
        "            # Yetkiyi belirle\n",
        "            permission = get_file_permission(filename, folder)\n",
        "\n",
        "            # Dosya türüne göre yönlendir\n",
        "            if folder == \"excel\" and (filename.endswith(\".xlsx\") or filename.endswith(\".xls\")):\n",
        "                processor.process_excel(file_path, permission)\n",
        "\n",
        "            elif folder == \"pdf\" and filename.endswith(\".pdf\"):\n",
        "                processor.process_standard_file(file_path, \"pdf\", permission)\n",
        "\n",
        "            elif folder == \"word\" and (filename.endswith(\".docx\") or filename.endswith(\".doc\")):\n",
        "                processor.process_standard_file(file_path, \"word\", permission)\n",
        "\n",
        "            elif folder == \"powerpoint\" and (filename.endswith(\".pptx\") or filename.endswith(\".ppt\")):\n",
        "                processor.process_standard_file(file_path, \"powerpoint\", permission)\n",
        "\n",
        "            else:\n",
        "\n",
        "                pass\n",
        "\n",
        "    # Çıktıyı Kaydet\n",
        "    output_file = \"/content/drive/MyDrive/1505 Chunking/tum_dokumanlar_chunked.pkl\"\n",
        "\n",
        "    if os.path.exists(BASE_PATH):\n",
        "\n",
        "         output_file = os.path.join(os.path.dirname(BASE_PATH), \"1505_chunk_output.pkl\")\n",
        "\n",
        "    processor.save_data(output_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg2modv4ONkS",
        "outputId": "3350d42a-80d4-4d1f-d6cd-45af6b75e215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tarama Başlıyor: /content/drive/MyDrive/1505 Chunking/Doküman\n",
            "\n",
            "[PDF] Klasörü Taranıyor...\n",
            "  -> PDF işlendi: 67 parça.\n",
            "  -> PDF işlendi: 53 parça.\n",
            "  -> PDF işlendi: 24 parça.\n",
            "  -> PDF işlendi: 103 parça.\n",
            "  -> PDF işlendi: 13 parça.\n",
            "  -> PDF işlendi: 51 parça.\n",
            "  -> PDF işlendi: 44 parça.\n",
            "  -> PDF işlendi: 21 parça.\n",
            "  -> PDF işlendi: 27 parça.\n",
            "  -> PDF işlendi: 22 parça.\n",
            "  -> PDF işlendi: 5 parça.\n",
            "  -> PDF işlendi: 7 parça.\n",
            "  -> PDF işlendi: 35 parça.\n",
            "  -> PDF işlendi: 7 parça.\n",
            "  -> PDF işlendi: 14 parça.\n",
            "  -> PDF işlendi: 5 parça.\n",
            "  -> PDF işlendi: 15 parça.\n",
            "  -> PDF işlendi: 7 parça.\n",
            "  -> PDF işlendi: 5 parça.\n",
            "  -> PDF işlendi: 3 parça.\n",
            "  -> PDF işlendi: 3 parça.\n",
            "  -> PDF işlendi: 4 parça.\n",
            "  -> PDF işlendi: 2 parça.\n",
            "  -> PDF işlendi: 2 parça.\n",
            "  -> PDF işlendi: 2 parça.\n",
            "  -> PDF işlendi: 2 parça.\n",
            "  -> PDF işlendi: 3 parça.\n",
            "  -> PDF işlendi: 4 parça.\n",
            "  -> PDF işlendi: 6 parça.\n",
            "  -> PDF işlendi: 26 parça.\n",
            "  -> PDF işlendi: 5 parça.\n",
            "  -> PDF işlendi: 4 parça.\n",
            "  -> PDF işlendi: 9 parça.\n",
            "\n",
            "[EXCEL] Klasörü Taranıyor...\n",
            "  -> Excel işlendi: 1 sayfa.\n",
            "  -> Excel işlendi: 1 sayfa.\n",
            "  -> Excel işlendi: 1 sayfa.\n",
            "\n",
            "[WORD] Klasörü Taranıyor...\n",
            "  (Klasör boş)\n",
            "\n",
            "[POWERPOINT] Klasörü Taranıyor...\n",
            "  -> POWERPOINT işlendi: 3 parça.\n",
            "\n",
            "Toplam 754 chunk kaydedildi: /content/drive/MyDrive/1505 Chunking/1505_chunk_output.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*view*"
      ],
      "metadata": {
        "id": "XR20i5uYO2tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "UtnYzoSuO0dz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from langchain.docstore.document import Document\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    print(\"Gerekli kütüphane (langchain) kuruluyor...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langchain\", \"langchain-community\"])\n",
        "    from langchain.docstore.document import Document\n"
      ],
      "metadata": {
        "id": "4oGEDv-6PkDz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "POSSIBLE_PATHS = [\n",
        "    \"/content/drive/MyDrive/1505 Chunking/processed_chunks_data.pkl\",\n",
        "    \"/content/drive/MyDrive/1505 Chunking/1505_chunk_output.pkl\",\n",
        "    \"/content/drive/MyDrive/1505 Chunking/tum_dokumanlar_chunked.pkl\"\n",
        "]\n",
        "\n",
        "def find_file():\n",
        "    for path in POSSIBLE_PATHS:\n",
        "        if os.path.exists(path):\n",
        "            return path\n",
        "    return None\n",
        "\n",
        "def preview_data(file_path):\n",
        "    print(f\"Dosya Yükleniyor: {file_path} ...\")\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            chunks = pickle.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"HATA: Dosya okunamadı. {e}\")\n",
        "        return\n",
        "\n",
        "    total_count = len(chunks)\n",
        "    print(f\"Başarıyla Yüklendi! Toplam Chunk Sayısı: {total_count}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\n>>> İlk 10 Chunk\")\n",
        "    for i, chunk in enumerate(chunks[:10]):\n",
        "        source = chunk.metadata.get('source', 'Bilinmiyor')\n",
        "        perm = chunk.metadata.get('permission', 'Yok')\n",
        "        content_preview = chunk.page_content.replace('\\n', ' ')[:100]\n",
        "\n",
        "        print(f\"[{i+1}] Dosya: {source} | Yetki: {perm}\")\n",
        "        print(f\"    İçerik: {content_preview}...\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    print(f\"\\n>>> Dosya Türü Bazlı Örnekler\")\n",
        "\n",
        "    target_types = [\"pdf\", \"excel\", \"word\", \"powerpoint\"]\n",
        "    # Türlere göre grupla\n",
        "    samples = {t: [] for t in target_types}\n",
        "\n",
        "    for chunk in chunks:\n",
        "        ftype = chunk.metadata.get(\"file_type\", \"unknown\")\n",
        "        if ftype in samples and len(samples[ftype]) < 3:\n",
        "            samples[ftype].append(chunk)\n",
        "\n",
        "    for ftype in target_types:\n",
        "        items = samples.get(ftype, [])\n",
        "        print(f\"\\n--- TÜR: {ftype.upper()} ({len(items)} örnek gösteriliyor) ---\")\n",
        "\n",
        "        if not items:\n",
        "            print(\"   (Bu dosya türüne ait veri bulunamadı)\")\n",
        "            continue\n",
        "\n",
        "        for idx, item in enumerate(items):\n",
        "            if ftype == 'excel':\n",
        "                loc_label = \"Satır\"\n",
        "                loc_val = item.metadata.get('row_number', '?')\n",
        "            else:\n",
        "                loc_label = \"Sayfa\"\n",
        "                loc_val = item.metadata.get('page_number', '?')\n",
        "\n",
        "            src = item.metadata.get('source')\n",
        "            text = item.page_content.replace('\\n', ' ')[:150]\n",
        "\n",
        "            print(f\"{idx+1}. {src} ({loc_label}: {loc_val})\")\n",
        "            print(f\"   Veri: {text}...\")\n"
      ],
      "metadata": {
        "id": "WlbUaYvTPpsj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "found_path = find_file()\n",
        "\n",
        "if found_path:\n",
        "    preview_data(found_path)\n",
        "else:\n",
        "    print(\"HATA: .pkl dosyası bulunamadı!\")\n",
        "    print(\"Lütfen aşağıdaki yolları kontrol edin veya dosya yolunu manuel olarak düzeltin:\")\n",
        "    for p in POSSIBLE_PATHS:\n",
        "        print(f\" - {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZlxY-1AQCyN",
        "outputId": "863dcc12-38aa-4b28-ed57-ac9532b340aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dosya Yükleniyor: /content/drive/MyDrive/1505 Chunking/1505_chunk_output.pkl ...\n",
            "Başarıyla Yüklendi! Toplam Chunk Sayısı: 754\n",
            "============================================================\n",
            "\n",
            ">>> İlk 10 Chunk\n",
            "[1] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: Senato Karar Eki    BURSA ULUDAĞ ÜNİVERSİTESİ İŞ SAĞLIĞI VE GÜVENLİĞİ YÖNERGESİ  BİRİNCİ BÖLÜM  Amaç...\n",
            "------------------------------\n",
            "[2] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: Tanımlar  MADDE 4- (1) Bu Yönerge’de geçen,  a) Acil durum: İşyerinin tamamında veya bir kısmında me...\n",
            "------------------------------\n",
            "[3] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: d) Birim: Bir işyeri sosyal güvenlik sicil numarası ve/veya birim NACE kod numarasına  sahip olup İş...\n",
            "------------------------------\n",
            "[4] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: Senato Karar Eki    f) Çalışan: Çırak ve stajyerler dahil kendi özel kanunlarındaki statülerine bakı...\n",
            "------------------------------\n",
            "[5] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: sahip kişileri,  ı) Geçici iş ilişkisi: Eğitim, görevlendirme gibi nedenlerle kadrosunun bulunduğu  ...\n",
            "------------------------------\n",
            "[6] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: l) İş kazası: İşyerinde veya işin yürütümü nedeniyle meydana gelen, ölüme sebebiyet  veren veya vücu...\n",
            "------------------------------\n",
            "[7] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: Senato Karar Eki    müdürünü, meslek yüksekokulu müdürlerini, merkez müdürlerini, genel sekreteri , ...\n",
            "------------------------------\n",
            "[8] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: uygun, kayıp veya yaralanma oluşturmayacak risk seviyesini,  t) Kanun: 6331 sayılı İş Sağlığı ve Güv...\n",
            "------------------------------\n",
            "[9] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: bütün haline getirilmiş cihaz, alet veya malzemeden oluşmuş donanımı, ayrılabilir veya  ayrılamaz ni...\n",
            "------------------------------\n",
            "[10] Dosya: 207858.pdf | Yetki: user\n",
            "    İçerik: Senato Karar Eki    işyerlerine İSG hizmetlerini sunmak üzere kurulan gerekli donanım ve personele s...\n",
            "------------------------------\n",
            "\n",
            ">>> Dosya Türü Bazlı Örnekler\n",
            "\n",
            "--- TÜR: PDF (3 örnek gösteriliyor) ---\n",
            "1. 207858.pdf (Sayfa: 1)\n",
            "   Veri: Senato Karar Eki    BURSA ULUDAĞ ÜNİVERSİTESİ İŞ SAĞLIĞI VE GÜVENLİĞİ YÖNERGESİ  BİRİNCİ BÖLÜM  Amaç, Kapsam, Dayanak ve Tanımlar  Amaç  MADDE 1- (1) ...\n",
            "2. 207858.pdf (Sayfa: 1)\n",
            "   Veri: Tanımlar  MADDE 4- (1) Bu Yönerge’de geçen,  a) Acil durum: İşyerinin tamamında veya bir kısmında meydana gelebilecek yangın,  patlama, tehlikeli kimy...\n",
            "3. 207858.pdf (Sayfa: 1)\n",
            "   Veri: d) Birim: Bir işyeri sosyal güvenlik sicil numarası ve/veya birim NACE kod numarasına  sahip olup İş Sağlığı ve Güvenliği (İSG) mevzuatında işyeri ola...\n",
            "\n",
            "--- TÜR: EXCEL (3 örnek gösteriliyor) ---\n",
            "1. Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx (Satır: 1)\n",
            "   Veri: Tablo: Fiyat Listesi, Satır: 1 Ürün Kodu: BIL-25-001 Ürün Adı: Bilimp CRM Modülü Kategori: Yazılım Lisansı Birim: Kullanıcı Liste Fiyatı: 5082 İndirim...\n",
            "2. Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx (Satır: 2)\n",
            "   Veri: Tablo: Fiyat Listesi, Satır: 2 Ürün Kodu: BIL-25-002 Ürün Adı: Bilimp Proje Yönetimi Kategori: Yazılım Lisansı Birim: Kullanıcı Liste Fiyatı: 13146 İn...\n",
            "3. Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx (Satır: 3)\n",
            "   Veri: Tablo: Fiyat Listesi, Satır: 3 Ürün Kodu: BIL-25-003 Ürün Adı: Bilimp Stok & Envanter Kategori: Yazılım Lisansı Birim: Kullanıcı Liste Fiyatı: 13752 İ...\n",
            "\n",
            "--- TÜR: WORD (0 örnek gösteriliyor) ---\n",
            "   (Bu dosya türüne ait veri bulunamadı)\n",
            "\n",
            "--- TÜR: POWERPOINT (3 örnek gösteriliyor) ---\n",
            "1. Bilimp_Satis_Sunum_Ornek_Sablon.pptx (Sayfa: 1)\n",
            "   Veri: Bilimp Öneri Aracı  © Bilimp Yazılım 2020    Rekabet koşullarının ağırlığı  şirketleri sürekli daha iyi olmaya yani sürekli iyileşmeye zorlamaktadır. ...\n",
            "2. Bilimp_Satis_Sunum_Ornek_Sablon.pptx (Sayfa: 1)\n",
            "   Veri: Çalışan memnuniyetini ve bağlılığını artırır  Kazan kazan ilkesi ile motivasyonu artırır  © Bilimp Yazılım 2020    Öneri Kayıt  Çalışanlar veya dış ku...\n",
            "3. Bilimp_Satis_Sunum_Ornek_Sablon.pptx (Sayfa: 1)\n",
            "   Veri: © Bilimp Yazılım 2020    Bilimp’i keşfedin.  Dijital yaşamın kolaylıklarını Bilimp ile keşfetmek için hemen şimdi ücretsiz deneyin.  www.bilimp.com  ©...\n"
          ]
        }
      ]
    }
  ]
}