"""
Tam Entegrasyon Ã–rneÄŸi: Embedding + Qdrant

Bu script, embedding modelinden gelen vektÃ¶rlerin Qdrant'a nasÄ±l kaydedileceÄŸini
ve nasÄ±l aranacaÄŸÄ±nÄ± gÃ¶sterir.

Bu Ã¶rnek, docs/5_complete_workflow.md dosyasÄ±ndaki "AdÄ±m 2: Veri Toplama ve Ã–n Ä°ÅŸleme"
kÄ±smÄ±nÄ± simÃ¼le eder.

GÃ¶revliler: SÃ¼leyman, Eren (Qdrant), Mehmet, Hasan (Embedding)
"""

import sys
import os

# src klasÃ¶rÃ¼nÃ¼ Python path'ine ekle
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from qdrant_client_manager import QdrantManager


def simulate_embedding_workflow():
    """
    Embedding modÃ¼lÃ¼nden gelen vektÃ¶rlerin Qdrant'a kaydedilmesi
    
    Bu fonksiyon, gerÃ§ek uygulamada ÅŸu ÅŸekilde Ã§alÄ±ÅŸacak:
    1. Chunking modÃ¼lÃ¼ (Engin, Batuhan) dokÃ¼manlarÄ± parÃ§alara ayÄ±rÄ±r
    2. Embedding modÃ¼lÃ¼ (Mehmet, Hasan) her parÃ§ayÄ± vektÃ¶rleÅŸtirir
    3. Qdrant modÃ¼lÃ¼ (SÃ¼leyman, Eren) vektÃ¶rleri kaydeder
    """
    
    print("=" * 70)
    print("ğŸ”„ TAM ENTEGRASYON Ã–RNEÄÄ°: EMBEDDING + QDRANT")
    print("=" * 70)
    
    # SimÃ¼le edilmiÅŸ chunking Ã§Ä±ktÄ±sÄ± (Engin, Batuhan'Ä±n Ã§alÄ±ÅŸmasÄ±)
    print("\n1ï¸âƒ£ DokÃ¼manlar parÃ§alanÄ±yor (Chunking)...")
    chunks = [
        {
            "id": 1,
            "content": "Python programlama dili, yÃ¼ksek seviyeli bir dildir.",
            "metadata": {
                "source": "python_kitap.pdf",
                "page": 15,
                "chapter": "GiriÅŸ"
            }
        },
        {
            "id": 2,
            "content": "Makine Ã¶ÄŸrenmesi, yapay zekanÄ±n bir alt dalÄ±dÄ±r.",
            "metadata": {
                "source": "ml_kitap.pdf",
                "page": 3,
                "chapter": "Temel Kavramlar"
            }
        },
        {
            "id": 3,
            "content": "Qdrant, vektÃ¶r veritabanÄ± iÃ§in kullanÄ±lan bir araÃ§tÄ±r.",
            "metadata": {
                "source": "veritabani_kitap.pdf",
                "page": 42,
                "chapter": "VektÃ¶r VeritabanlarÄ±"
            }
        },
        {
            "id": 4,
            "content": "TÃœBÄ°TAK 1505 projesi, kurumsal dokÃ¼man danÄ±ÅŸmanÄ± geliÅŸtiriyor.",
            "metadata": {
                "source": "proje_dokuman.pdf",
                "page": 1,
                "chapter": "Ã–zet"
            }
        }
    ]
    print(f"   âœ… {len(chunks)} chunk oluÅŸturuldu")
    
    # SimÃ¼le edilmiÅŸ embedding Ã§Ä±ktÄ±sÄ± (Mehmet, Hasan'Ä±n Ã§alÄ±ÅŸmasÄ±)
    # GerÃ§ek uygulamada: turkish-e5-large modeli ile 1024 boyutlu vektÃ¶rler
    print("\n2ï¸âƒ£ Chunk'lar vektÃ¶rleÅŸtiriliyor (Embedding - Turkish-E5-Large)...")
    embeddings_data = []
    for chunk in chunks:
        # SimÃ¼le edilmiÅŸ embedding vektÃ¶rÃ¼
        # GerÃ§ekte: embeddings.embed_query(chunk["content"]) kullanÄ±lacak
        simulated_vector = [float(chunk["id"]) * 0.1] * 1024
        
        embeddings_data.append({
            "id": chunk["id"],
            "vector": simulated_vector,
            "content": chunk["content"],
            "metadata": chunk["metadata"]
        })
    print(f"   âœ… {len(embeddings_data)} vektÃ¶r oluÅŸturuldu (1024-dimensional)")
    
    # Qdrant'a kaydetme (SÃ¼leyman, Eren'in Ã§alÄ±ÅŸmasÄ±)
    print("\n3ï¸âƒ£ VektÃ¶rler Qdrant'a kaydediliyor...")
    qdrant = QdrantManager(host="localhost", port=6333)
    
    collection_name = "tubitak_documents"
    
    # Koleksiyon oluÅŸtur (eÄŸer yoksa)
    if qdrant.collection_exists(collection_name):
        print(f"   âš ï¸ '{collection_name}' zaten mevcut")
    else:
        qdrant.create_collection(
            collection_name=collection_name,
            vector_size=1024  # Cosmos-E5-Large iÃ§in
        )
    
    # VektÃ¶rleri Qdrant'a ekle
    points = []
    for item in embeddings_data:
        points.append({
            "id": item["id"],
            "vector": item["vector"],
            "payload": {
                "content": item["content"],
                "source": item["metadata"]["source"],
                "page": item["metadata"]["page"],
                "chapter": item["metadata"]["chapter"]
            }
        })
    
    qdrant.upsert_points(collection_name, points)
    
    # Koleksiyon bilgilerini gÃ¶ster
    print("\n4ï¸âƒ£ Koleksiyon bilgileri:")
    info = qdrant.get_collection_info(collection_name)
    if info:
        print(f"   ğŸ“Š Koleksiyon: {info['name']}")
        print(f"   ğŸ“Š Toplam VektÃ¶r: {info['vectors_count']}")
        print(f"   ğŸ“Š VektÃ¶r Boyutu: {info['vector_size']}")
        print(f"   ğŸ“Š Mesafe: {info['distance']}")
    
    # KullanÄ±cÄ± sorgusunu simÃ¼le et
    print("\n5ï¸âƒ£ KullanÄ±cÄ± sorgusu simÃ¼lasyonu...")
    user_query = "Makine Ã¶ÄŸrenmesi nedir?"
    print(f"   ğŸ‘¤ KullanÄ±cÄ± Sorusu: '{user_query}'")
    
    # Sorgu vektÃ¶rÃ¼ oluÅŸtur (gerÃ§ekte embedding modeli kullanÄ±lacak)
    # query_vector = embeddings.embed_query(user_query)
    query_vector = [0.2] * 1024  # SimÃ¼le edilmiÅŸ sorgu vektÃ¶rÃ¼
    
    # Qdrant'ta arama yap
    print("\n6ï¸âƒ£ Qdrant'ta semantik arama yapÄ±lÄ±yor...")
    results = qdrant.search(
        collection_name=collection_name,
        query_vector=query_vector,
        limit=3
    )
    
    print(f"\n   ğŸ“ En Ä°lgili {len(results)} SonuÃ§:")
    for i, result in enumerate(results, 1):
        print(f"\n   {i}. SonuÃ§ (Benzerlik: {result['score']:.4f})")
        print(f"      ğŸ’¬ Ä°Ã§erik: {result['payload']['content']}")
        print(f"      ğŸ“„ Kaynak: {result['payload']['source']}")
        print(f"      ğŸ“– Sayfa: {result['payload']['page']}")
        print(f"      ğŸ“š BÃ¶lÃ¼m: {result['payload']['chapter']}")
    
    # FiltrelenmiÅŸ arama Ã¶rneÄŸi
    print("\n7ï¸âƒ£ FiltrelenmiÅŸ arama (sadece 'ml_kitap.pdf')...")
    filtered_results = qdrant.search(
        collection_name=collection_name,
        query_vector=query_vector,
        limit=5,
        filter_conditions={"source": "ml_kitap.pdf"}
    )
    
    print(f"   ğŸ“ FiltrelenmiÅŸ SonuÃ§lar: {len(filtered_results)} sonuÃ§")
    for result in filtered_results:
        print(f"      - {result['payload']['content'][:50]}...")
    
    # GerÃ§ek workflow'da sonraki adÄ±m (Hasan, Eren'in Ã§alÄ±ÅŸmasÄ±)
    print("\n8ï¸âƒ£ Sonraki AdÄ±m: LLM ile YanÄ±t Ãœretimi")
    print("   ğŸ¤– Bulunan context'ler LLM'e (Gemma3-12B/Qwen3-8B) gÃ¶nderilecek")
    print("   ğŸ¤– LLM, bu bilgilere dayanarak kullanÄ±cÄ±ya yanÄ±t Ã¼retecek")
    
    # BaÄŸlantÄ±yÄ± kapat
    qdrant.close()
    
    print("\n" + "=" * 70)
    print("âœ… Entegrasyon Ã¶rneÄŸi tamamlandÄ±!")
    print("=" * 70)
    
    # GerÃ§ek workflow Ã¶zeti
    print("\nğŸ“‹ GERÃ‡EK Ä°Å AKIÅI Ã–ZETÄ°:")
    print("   1. Engin, Batuhan â†’ Chunking")
    print("   2. Mehmet, Hasan â†’ Embedding (turkish-e5-large)")
    print("   3. SÃ¼leyman, Eren â†’ Qdrant'a kaydetme (bu modÃ¼l)")
    print("   4. KullanÄ±cÄ± sorgusu â†’ Embedding")
    print("   5. Qdrant'ta arama â†’ Context bulma")
    print("   6. Hasan, Eren â†’ LLM ile yanÄ±t Ã¼retimi")
    print("   7. KullanÄ±cÄ±ya yanÄ±t sunumu")


def real_world_example_with_notes():
    """
    GerÃ§ek projede nasÄ±l kullanÄ±lacaÄŸÄ±na dair kod Ã¶rneÄŸi
    """
    print("\n\n" + "=" * 70)
    print("ğŸ“– GERÃ‡EK PROJE KULLANIMI")
    print("=" * 70)
    
    print("""
Bu modÃ¼l gerÃ§ek projede ÅŸu ÅŸekilde kullanÄ±lacak:

# 1. Chunking modÃ¼lÃ¼nden chunks al (Engin, Batuhan)
from chunking_module import ChunkingProcessor
chunking = ChunkingProcessor()
chunks = chunking.process_documents(['doc1.pdf', 'doc2.pdf'])

# 2. Embedding modÃ¼lÃ¼ ile vektÃ¶rleÅŸtir (Mehmet, Hasan)
from langchain_huggingface import HuggingFaceEmbeddings
embeddings = HuggingFaceEmbeddings(
    model_name="ytu-ce-cosmos/turkish-e5-large"
)

# 3. Qdrant'a kaydet (SÃ¼leyman, Eren)
from qdrant_client_manager import QdrantManager
qdrant = QdrantManager()
qdrant.create_collection("documents", vector_size=1024)

points = []
for i, chunk in enumerate(chunks):
    vector = embeddings.embed_query(chunk.page_content)
    points.append({
        "id": i,
        "vector": vector,
        "payload": {
            "content": chunk.page_content,
            "metadata": chunk.metadata
        }
    })

qdrant.upsert_points("documents", points)

# 4. KullanÄ±cÄ± sorgusunu iÅŸle
user_query = "TÃœBÄ°TAK 1505 nedir?"
query_vector = embeddings.embed_query(user_query)

# 5. Ä°lgili dokÃ¼manlarÄ± bul
results = qdrant.search("documents", query_vector, limit=5)

# 6. LLM ile yanÄ±t Ã¼ret (Hasan, Eren)
from llm_module import LLMGenerator
llm = LLMGenerator(model="gemma3-12b")
context = "\n".join([r['payload']['content'] for r in results])
response = llm.generate_response(user_query, context)

print(response)
    """)


if __name__ == "__main__":
    try:
        simulate_embedding_workflow()
        real_world_example_with_notes()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan iptal edildi.")
    except Exception as e:
        print(f"\n\nâŒ Hata oluÅŸtu: {e}")
        import traceback
        traceback.print_exc()
