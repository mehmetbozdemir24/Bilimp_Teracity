"""
Embedding ModÃ¼lÃ¼ KullanÄ±m Ã–rneÄŸi

âš ï¸ DÄ°KKAT: Bu script HuggingFace'den model indirdiÄŸi iÃ§in internet baÄŸlantÄ±sÄ± gerektirir.

Bu script, docs/2_embedding_guide.md'deki Ã¶rnekleri gÃ¶sterir.
"""

import sys
import os

# Proje kÃ¶k dizinini path'e ekle
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import torch
from langchain_core.documents import Document
from src.embedding import EmbeddingProcessor


def main():
    print("="*60)
    print("EMBEDDING MODÃœLÃœ KULLANIM Ã–RNEÄžÄ°")
    print("="*60)
    
    # GPU/CPU kontrolÃ¼
    print(f"\nðŸ–¥ï¸  GPU KullanÄ±labilir: {torch.cuda.is_available()}")
    
    # Model yÃ¼kleme
    print("\nðŸ“¥ Model yÃ¼kleniyor...")
    processor = EmbeddingProcessor()
    
    # Test 1: Tek metin vektÃ¶rleme
    print("\n" + "="*60)
    print("TEST 1: Tek Metin VektÃ¶rleme")
    print("="*60)
    
    text = "Python programlama dilidir"
    embedding = processor.embed_query(text)
    print(f"Metin: '{text}'")
    print(f"Embedding boyutu: {len(embedding)}")
    print(f"Ä°lk 5 deÄŸer: {embedding[:5]}")
    
    # Test 2: Basit chunk listesi
    print("\n" + "="*60)
    print("TEST 2: Basit Chunk Listesi")
    print("="*60)
    
    chunks = [
        "Python programlama dilidir",
        "Makine Ã¶ÄŸrenmesi yapay zekadÄ±r"
    ]
    embeddings_list = processor.embed_documents(chunks)
    print(f"âœ… {len(embeddings_list)} chunk vektÃ¶rleÅŸtirildi!")
    
    for i, (chunk, emb) in enumerate(zip(chunks, embeddings_list)):
        print(f"  Chunk {i+1}: '{chunk}' -> VektÃ¶r boyutu: {len(emb)}")
    
    # Test 3: LangChain Document chunks
    print("\n" + "="*60)
    print("TEST 3: LangChain Document Chunks")
    print("="*60)
    
    documents = [
        Document(
            page_content="Python programlama dilidir",
            metadata={"source": "ders1.pdf", "page": 1}
        ),
        Document(
            page_content="Makine Ã¶ÄŸrenmesi yapay zekadÄ±r",
            metadata={"source": "ders2.pdf", "page": 2}
        ),
        Document(
            page_content="LangChain gÃ¼Ã§lÃ¼ bir framework'tÃ¼r",
            metadata={"source": "ders3.pdf", "page": 3}
        ),
    ]
    
    embeddings_dict = processor.process_chunks(documents, batch_size=2)
    print(f"\nðŸ“Š Ä°ÅŸlenen dokÃ¼mantasyon:")
    for idx, data in embeddings_dict.items():
        print(f"  [{idx}] {data['content'][:50]}...")
        print(f"      Kaynak: {data['metadata']['source']}")
        print(f"      VektÃ¶r boyutu: {len(data['embedding'])}")
    
    # Test 4: Benzerlik hesaplama
    print("\n" + "="*60)
    print("TEST 4: Benzerlik Hesaplama")
    print("="*60)
    
    import numpy as np
    
    emb1 = processor.embed_query("Makine Ã¶ÄŸrenmesi yapay zekadÄ±r")
    emb2 = processor.embed_query("Yapay zeka makine Ã¶ÄŸrenmesidir")
    emb3 = processor.embed_query("BugÃ¼n hava Ã§ok gÃ¼zel")
    
    similarity_high = np.dot(emb1, emb2)
    similarity_low = np.dot(emb1, emb3)
    
    print(f"Benzer metinler arasÄ± benzerlik: {similarity_high:.4f}")
    print(f"FarklÄ± metinler arasÄ± benzerlik: {similarity_low:.4f}")
    
    # Test 5: Kaydetme ve yÃ¼kleme
    print("\n" + "="*60)
    print("TEST 5: Embedding Kaydetme ve YÃ¼kleme")
    print("="*60)
    
    output_path = "/tmp/embeddings_example.pkl"
    processor.save_embeddings(embeddings_dict, output_path)
    
    loaded_dict = processor.load_embeddings(output_path)
    print(f"âœ… YÃ¼kleme baÅŸarÄ±lÄ±! {len(loaded_dict)} embedding bulundu.")
    
    # Test 6: Model bilgileri
    print("\n" + "="*60)
    print("MODEL BÄ°LGÄ°LERÄ°")
    print("="*60)
    print(f"Model: {processor.model_name}")
    print(f"Device: {processor.device}")
    print(f"Embedding boyutu: {processor.get_embedding_dimension()}")
    
    print("\n" + "="*60)
    print("âœ… TÃœM TESTLER TAMAMLANDI!")
    print("="*60)


if __name__ == "__main__":
    main()
